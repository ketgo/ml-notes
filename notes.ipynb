{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducation\n",
    "\n",
    "- Machine learning invloves constructing statisitcal models by utilizing observed data.\n",
    "- A statistical model represents, often in considerably idealized form, the data-generating process.\n",
    "- In mathematical terms, a statistical model is usually thought of as a pair $(\\mathcal {S}, \\mathcal {P})$, where $S$ is the set of possible observations, i.e. the sample space, and ${\\mathcal {P}}$ is a set of probability distributions on $S$.\n",
    "- The set ${\\mathcal {P}}$ is almost always parameterized: ${\\mathcal {P}}=\\{P_{\\theta }:\\theta \\in \\Theta \\}$. The set $\\Theta$ defines the parameters of the model.\n",
    "- Staistical inference is used to validate the parameters $\\Theta$ through training and generalization errors.\n",
    "\n",
    "### Example\n",
    "\n",
    "Suppose that we have a population of children, with the ages of the children distributed uniformly, in the population. The height of a child will be stochastically related to the age: e.g. when we know that a child is of age 7, this influences the chance of the child being 1.5 meters tall. We could formalize that relationship in a linear regression model, like this: heighti = b0 + b1agei + εi, where b0 is the intercept, b1 is a parameter that age is multiplied by to obtain a prediction of height, εi is the error term, and i identifies the child. This implies that height is predicted by age, with some error.\n",
    "\n",
    "An admissible model must be consistent with all the data points. Thus, a straight line (heighti = b0 + b1agei) cannot be the equation for a model of the data—unless it exactly fits all the data points, i.e. all the data points lie perfectly on the line. The error term, εi, must be included in the equation, so that the model is consistent with all the data points.\n",
    "\n",
    "To do statistical inference, we would first need to assume some probability distributions for the εi. For instance, we might assume that the εi distributions are i.i.d. Gaussian, with zero mean. In this instance, the model would have 3 parameters: b0, b1, and the variance of the Gaussian distribution.\n",
    "\n",
    "We can formally specify the model in the form ( S , P {\\displaystyle S,{\\mathcal {P}}} S,{\\mathcal {P}}) as follows. The sample space, S {\\displaystyle S} S, of our model comprises the set of all possible pairs (age, height). Each possible value of θ {\\displaystyle \\theta } \\theta  = (b0, b1, σ2) determines a distribution on S {\\displaystyle S} S; denote that distribution by P θ {\\displaystyle P_{\\theta }} P_{{\\theta }}. If Θ {\\displaystyle \\Theta } \\Theta is the set of all possible values of θ {\\displaystyle \\theta } \\theta , then P = { P θ : θ ∈ Θ } {\\displaystyle {\\mathcal {P}}=\\{P_{\\theta }:\\theta \\in \\Theta \\}} {\\mathcal {P}}=\\{P_{{\\theta }}:\\theta \\in \\Theta \\}. (The parameterization is identifiable, and this is easy to check.)\n",
    "\n",
    "In this example, the model is determined by (1) specifying S {\\displaystyle S} S and (2) making some assumptions relevant to P {\\displaystyle {\\mathcal {P}}} {\\mathcal {P}}. There are two assumptions: that height can be approximated by a linear function of age; that errors in the approximation are distributed as i.i.d. Gaussian. The assumptions are sufficient to specify P {\\displaystyle {\\mathcal {P}}} {\\mathcal {P}}—as they are required to do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "\n",
    "Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicitive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning\n",
    "\n",
    "Unsupervised learning is a type of algorithm that learns patterns from untagged data. The hope is that through mimicry, the machine is forced to build a compact internal representation of its world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducation\n",
    "\n",
    "- Machine learning invloves constructing statisitcal models by utilizing observed data.\n",
    "- A statistical model represents, often in considerably idealized form, the data-generating process.\n",
    "- In mathematical terms, a statistical model is usually thought of as a pair $(\\mathcal {S}, \\mathcal {P})$, where $S$ is the set of possible observations, i.e. the sample space, and ${\\mathcal {P}}$ is a set of probability distributions on $S$.\n",
    "- The set ${\\mathcal {P}}$ is almost always parameterized: ${\\mathcal {P}}=\\{P_{\\theta }:\\theta \\in \\Theta \\}$. The set $\\Theta$ defines the parameters of the model.\n",
    "- Staistical inference is used to validate the parameters $\\Theta$ through training and generalization errors.\n",
    "\n",
    "### Example\n",
    "\n",
    "Suppose that we have a population of children, with the ages of the children distributed uniformly, in the population. The height of a child will be stochastically related to the age: e.g. when we know that a child is of age 7, this influences the chance of the child being 1.5 meters tall. We could formalize that relationship in a linear regression model, like this: $height_i = b_0 + b_1 age_i + ε_i$, where $b_0$ is the intercept, $b_1$ is a parameter that age is multiplied by to obtain a prediction of height, $ε_i$ is the error term, and i identifies the child. This implies that height is predicted by age, with some error.\n",
    "\n",
    "An admissible model must be consistent with all the data points. Thus, a straight line ($height_i = b_0 + b_1 age_i$) cannot be the equation for a model of the data—unless it exactly fits all the data points, i.e. all the data points lie perfectly on the line. The error term, εi, must be included in the equation, so that the model is consistent with all the data points.\n",
    "\n",
    "To do statistical inference, we would first need to assume some probability distributions for the εi. For instance, we might assume that the εi distributions are i.i.d. Gaussian, with zero mean. In this instance, the model would have 3 parameters: b0, b1, and the variance of the Gaussian distribution.\n",
    "\n",
    "We can formally specify the model in the form $(\\mathcal {S}, \\mathcal {P})$ as follows. The sample space, $\\mathcal{S}$, of our model comprises the set of all possible pairs (age, height). Each possible value of $\\theta  = (b_0, b_1, \\sigma_2)$ determines a distribution on $\\mathcal{S}$; denote that distribution by $P_\\Theta$. If $\\Theta$ is the set of all possible values of $\\theta$ , then ${\\mathcal {P}}=\\{P_{{\\theta }}:\\theta \\in \\Theta \\}$. (The parameterization is identifiable, and this is easy to check.)\n",
    "\n",
    "In this example, the model is determined by (1) specifying $\\mathcal{S}$ and (2) making some assumptions relevant to $\\mathcal{P}$. There are two assumptions: that height can be approximated by a linear function of age; that errors in the approximation are distributed as i.i.d. Gaussian. The assumptions are sufficient to specify $\\mathcal{P}$ —as they are required to do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "\n",
    "Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classification predictor ($G(x)$).\n",
    "- Models the posterior probablilty $P(G=k | X=x)$ of K classes via linear functions.\n",
    "- The model has the form: $$\\ln \\frac{P(G=k | X=x)}{P(G=l | X=x)} = \\theta_{k, 0} + \\theta_{k, 1}^T x$$\n",
    "- Although the last class is used as dominator in the odds-ratios, the choice of denominator is aribitrary.\n",
    "- The posterior probability is given by: $$P(G=k | X=x) = \\frac{\\exp(\\theta_{k, 0} + \\theta_{k, 1}^T x)}{1 + \\sum_{l=1}^{K-1} \\exp(\\theta_{l, 0} + \\theta_{l, 1}^T x)}$$ $$P(G=K | X=x) = \\frac{1}{1 + \\sum_{l=1}^{K-1} \\exp(\\theta_{l, 0} + \\theta_{l, 1}^T x)}$$\n",
    "- Loss function: $L(\\Theta) = \\sum_{i=1}^{N} \\ln P(G=y_i | X=x_i)$ where $N$ is the sample size. The loss function is the log-likelihood for the $N$ observations. The best estimates of the parameters is when the log-likelihood is maxomized. \n",
    "- Alternatly loss function:  $L(\\Theta) = - \\sum_{i=1}^{N} \\ln P(G=y_i | X=x_i)$. Here the loss function is the information content in the N observations. Training attempts to capture the infromation in the data which in turn results in decrease of the remaining information content in the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning\n",
    "\n",
    "Unsupervised learning is a type of algorithm that learns patterns from untagged data. The hope is that through mimicry, the machine is forced to build a compact internal representation of its world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Assesment and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
